# README RNAseq Pipeline

**Disclaimer:** This ReadMe serves as the instruction manual to run this pipeline successfully, it is NOT the Labbook and will therefore not go into detail about what each process does and what purpose it has, for infomration on this please consult the Labbook.
Here i will explain the steps that are necessary to run this pipeline as well as the outputs this pipeline generates.

### Resource requirements

A large amount of disk space is required, in my experience a good rule of thum is to multiply the size of all input files with 15 to get a reasonable estimate on how much spacce the data generated by this pipeline will need.
```bash
# Example
# input data: 20 GB
# necessary disk space:
total= 20 + (20*15)
total= 320
```

### setup of environment

This should be done according to ones own preference, i however would recommend the usage of a virtual machine running ubuntu (22.04)
as this was the environment in which this pipeline was created.
From here on it will be assumed that all functionalities that ubuntu natively provides are present.

### Installations

Nextflow should be installed according to Nextflows installation manual, note: this may change over time so the approach i took may be outdated at the time you are using this pipeline.

```bash
sudo apt install git
sudo apt install docker
sudo apt install openjdk-21-jdk
curl -s https://get.nextflow.io | bash
chmod +x nextflow
sudo mv /home/ubuntu/nextflow /bin # change the directory as necessary, nextflow mus be in the PATH
nextflow info # seves as confirmation of successful installation
sudo apt install tabix
```


### Docker

This pipeline uses many external tools besides Nextflow itself, all of them were run in Docker containers, which are then managed and started by Nextflow. The user does not need to manage any container, only the correct images must be downloaded. For this please pull the images with the RepoDigest provided in the table below as newer versions of these containers may behave differently than the ones i used. Please use this command to pull the images listed below:

```bash
docker pull name_of_image_here
```

**Images to be pulled**
| Tool | RepoDigest |
| ---- | ---------- |
| fastqc & TrimGalore! | community.wave.seqera.io/library/trim-galore@sha256:4f00e7b2a09f3c8d8a9ce955120e177152fb1e56f63a2a6e186088b1250d9907 |
| samtools | community.wave.seqera.io/library/samtools@sha256:5e5188b3dacf0117c4d4db891f2b9f4873d93288b4cfb26c1fba43eb7d241a4c |
| multiqc | community.wave.seqera.io/library/pip_multiqc@sha256:0ebb1d9605395a7df49ad0eb366b21f46afd96a5090376b0d8941cf5294a895a |
| bedtools | community.wave.seqera.io/library/bedtools@sha256:a49419dd283ad6a2e7bb00cab8f9d939b73581f1fe45fdbe774fd6cd9e652f48 |
| star | community.wave.seqera.io/library/star@sha256:25a18a65561065970d2bee3cc481949b58711c31b48499dd4e86df18aa69e3a8 |
| salmon | community.wave.seqera.io/library/salmon@sha256:b4519ea6d76868516e8c545fd709bf900638cb4b9130206730e09038b2e9e274 |
| bowtie2 | community.wave.seqera.io/library/bowtie2@sha256:7e95aab41e539b4696750e91020b20b09e45778688ebac01b3e3d03388aa6704 |
| kallisto | quay.io/biocontainers/kallisto@sha256:f2dc85d6d55e1c3bfdc437a7738b1217d0f81ee9c1c62013b5dd3b867713d482 |
| gffread | quay.io/biocontainers/gffread@sha256:f603c5f4c8fff454ab282e917068d91060794e1daa798cbde0c125ade72f189d |
| picard | community.wave.seqera.io/library/picard@sha256:e269216786463d44f9d83a0d6e877b34bca2c7b4d35211b4b369fe98e39ef1a5 |
| featurecounts | community.wave.seqera.io/library/subread@sha256:4b5569b45ab8d6f106b69cf5f682c34fce76e36871c8553f899eb54da58deb48 |



Some containers have to be set up by the user, to create these, please use the Dockerfiles provided below. Here it is important to use the **same** names for the names of the created images i used as nextflow will search for containers with these exact names. First please create a directory named after the name of the container, then go into this directory and create a Dockerfile like this (this may take a while):

```bash
mkdir python_vis
cd python_vis
nano Dockerfile

# now you are in the nano editor, please copy the Dockerfile provided below here, then save and exit

# after creating the Dockerfile like this, now you build the container with this command:
docker build -t python_vis .
# for the python container the name is "python_vis", for the R container use the Name of the R container instead
```
**python_vis**
```bash
FROM python:3.10-slim
RUN pip install --no-cache-dir numpy==1.26.0
RUN pip install --no-cache-dir pandas==2.2.3
RUN pip install --no-cache-dir matplotlib==3.7.1
RUN pip install --no-cache-dir seaborn==0.13.2
RUN apt-get update && apt-get install -y procps && rm -rf /var/lib/apt/lists/*
```

**r_tricho**
```bash
FROM r-base@sha256:089317f336a61255bb35f1efd799820cef37136d2acf2a76ba4abb74af51d4a3
RUN apt-get update && apt-get install -y libcurl4-openssl-dev libxml2-dev libssl-dev
RUN R -e "install.packages(c('BiocManager', 'tidyverse'))"
RUN R -e "BiocManager::install(c('edgeR', 'tximport', 'limma', 'DESeq2'))"
```

### nextflow.config

This is the config file for this pipeline, please look into this file before running the pipeline as it specifies resource allocations for a few key processes (the ones with the most requirements). Here the amount of cpus allocated to each process as well as memory allocation is specified, therefore it is imperative to check wether your machine can handle the allocations made here. Please change the allocations to fit your resources, note that larger input files will require more RAM, not just more disk space.

### params.yml / params2.yml

This file contains the actual values for each parameter. Here the user must insert the values/paths that fit his experiment, chief amongst them is the parameter "experiment" as this defines the exeriment, and defines a key directory where materials and results of the experiment will be located.
Most of these parameters don NOT need to be changed, the table below shows which parameter should be changed and which one should not be altered:

| change | keep |
| ------ | ---- |
| experiment | tpm_calc_script|
| infile | tx2_gene_script |
| fasta | edger |
| annotation | limma |
| --- | deseq2 |
| --- | vis_genome_coverage |
| --- | vis_gene_coverage |
| --- | vis_mq |
| --- | pseudo_coverage |
| --- | compare_tpms |
| --- | plot_edger |
| --- | plot_limma |
| --- | plot_deseq2 |


### read_paths.csv

This is a key file that must be created before running this pipeline as multiple processes depend on it, this is NOT optional.
This csv file must contain a name-pattern unique to each pair of reads (filenames of the read-pair must reflect it), the forward and reverse read as well as the condition of this read-pair. All 4 columns must have strings as values, a column without any values will result in errors.
Below is an example of how this file has to look (or just change the existing read_paths.csv file):

```bash
name,forward,reverse,condition
rep1_ph5_co004,yeast/material/rep1_ph5_co004_1.fastq.gz,yeast/material/rep1_ph5_co004_2.fastq.gz,control
```

### directory structure

The pipeline requires a distinct directory structure to run smoothly, the structure of the gitlab repository reflects this as well, below you find a brief structure of how this structure should look like, please note that the created docker images must be created in their own directory and that the images must be accessible to the directory in which nextflow runs.

 - rna
    - scripts
    - modules
    - whatever_experiment_is
        - material
            - all_fastq_files
            - reference fasta
            - gff file or gtf
            - read_paths.csv
        - results
    - params.yml
    - nextflow.config
    - rna_pipe.nf
    - Labbook.md
    - README.md

### running the pipeline

With all of this set up the pipeline **must** be run using this command (also dont run it with sudo, that only creates problems down the line):

```bash
nextflow run rna_pipe.nf -params-file params.yml -with-trace -with-report
```



